{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam_teste2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzaL_pVDlO88"
      },
      "source": [
        "#Bibliotecas usadas\r\n",
        "import pandas as pd\r\n",
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOb9VX-kl6NR",
        "outputId": "4c73f01f-bbac-4594-f56d-398096901774"
      },
      "source": [
        "#Ler o arquivo\r\n",
        "#Caso use o dataset na sua base garanta que o arquivo foi importado para o Colab e substitua a linha de leitura pela seguinte linha:\r\n",
        "#df = pd.read_csv('./sms_senior.csv', encoding= 'unicode_escape')\r\n",
        "df = pd.read_csv('http://llcunha.com/sms_senior.csv', encoding= 'unicode_escape')\r\n",
        "\r\n",
        "#Separar o dataframe em dois, as palavras comuns, que serão utilizadas para prever e as classificações já conhecidas\r\n",
        "words = df.drop(['Full_Text', 'Common_Word_Count', 'Word_Count', 'Date', 'IsSpam'], axis=1)\r\n",
        "classification = df['IsSpam']\r\n",
        "\r\n",
        "#Descobrir quanto e 80 porcento da base para que seja dividido em um dataframe de treino e um de testes com validacao\r\n",
        "numberOfCases = len(df.index)\r\n",
        "numberOfTraining = (numberOfCases * 80) // 100\r\n",
        "numberOfTests = numberOfCases - numberOfTraining\r\n",
        "\r\n",
        "#Define o que sera o dataframe de teste junto com as classificacoes e abaixo o que sera o de teste com a validacao\r\n",
        "training_x, training_y = words[0:numberOfTraining], classification[0:numberOfTraining]\r\n",
        "test_x, test_y = words[numberOfTests:numberOfCases], classification[numberOfTests:numberOfCases]\r\n",
        "\r\n",
        "#Cria o classificador e treina ele\r\n",
        "model = LinearSVC()\r\n",
        "model.fit(training_x, training_y)\r\n",
        "\r\n",
        "#Resultado das predicoes com o dataframe de teste\r\n",
        "previsoes = model.predict(test_x)\r\n",
        "\r\n",
        "#Compara as previsoes feitas com a classificacao conhecida do dataframe de teste que e usado para validacao e printa taxa de acerto\r\n",
        "corretos = (previsoes == test_y).sum()\r\n",
        "total = len(test_x)\r\n",
        "taxa_de_acerto = corretos/total\r\n",
        "print(\"Taxa de acerto %.2f\" % (taxa_de_acerto * 100))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taxa de acerto 97.11\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}